{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set() # prettify matplotlib\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.gaussian_process as gp\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turbo.gui as tg\n",
    "tg.jupyter_set_width('80%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: 1 * x * np.cos(x)\n",
    "f = lambda x: 100 * np.sin(x**2/5) * np.cos(x*1.5) + 100\n",
    "xmin, xmax = 0, 12\n",
    "xs = np.linspace(xmin, xmax, num=200)\n",
    "\n",
    "n = 8 # 8 is a good value to show overfitting\n",
    "#n = 200\n",
    "X = np.random.uniform(xmin, xmax, size=(n,1))\n",
    "y = f(X) + np.random.normal(0, 5, size=(n,1))\n",
    "\n",
    "ys = f(xs)\n",
    "best_y = np.min(ys)\n",
    "best_x = xs[np.argmin(ys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(xs, ys, 'g-', label='objective')\n",
    "plt.plot(X, y, 'ko', markersize=4, label='sampled points')\n",
    "plt.legend(loc='upper left')\n",
    "plt.margins(0.01, 0.1)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$f(x)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing GP models\n",
    "\n",
    "The function has been chosen to be particularly difficult for a GP to fit to with the following difficulties:\n",
    "- the range of y values is large so the kernel must be multiplied to get enough amplitude\n",
    "- the function does not have a mean of 0 so a bias is required in the kernel\n",
    "- there is not enough training data to accurately fit the function\n",
    "- there is noise added to the function value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GP(mean, sig, title=''):\n",
    "    mean = mean.flatten()\n",
    "    sig = sig.flatten()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(title)\n",
    "    plt.plot(xs, ys, '--', color='grey', label='true function')\n",
    "    plt.plot(X, y, 'bx', markersize=7, label='training samples')\n",
    "    plt.plot(xs, mean, label='GP prediction')\n",
    "    plt.fill_between(xs, mean-sig, mean+sig, label='GP prediction', alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GPs(means, sigs, title=''):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(title)\n",
    "    plt.plot(xs, ys, '--', color='grey', label='true function')\n",
    "    plt.plot(X, y, 'bx', markersize=7, label='training samples')\n",
    "    for i in range(means.shape[0]):\n",
    "        mean = means[i]\n",
    "        sig = sigs[i]\n",
    "        plt.plot(xs, mean, color='b')\n",
    "        plt.fill_between(xs, mean-sig, mean+sig, color='b', alpha=0.05)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1)\n",
    "gp_model = GPy.models.GPRegression(X, y, kernel=kernel)\n",
    "gp_model.optimize_restarts(messages=False, num_restarts=10);\n",
    "display(gp_model)\n",
    "\n",
    "mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "plot_GP(mean, np.sqrt(var), 'GPy 10 restarts RBF kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1) + GPy.kern.Bias(input_dim=1)\n",
    "gp_model = GPy.models.GPRegression(X, y, kernel=kernel)\n",
    "gp_model.optimize_restarts(messages=False, num_restarts=10);\n",
    "display(gp_model)\n",
    "\n",
    "mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "plot_GP(mean, np.sqrt(var), 'GPy 10 restarts RBF kernel + bias kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1)\n",
    "gp_model = GPy.models.GPRegression(X, y, kernel=kernel, normalizer=True)\n",
    "gp_model.optimize_restarts(messages=False, num_restarts=10);\n",
    "display(gp_model)\n",
    "\n",
    "mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "plot_GP(mean, np.sqrt(var), 'GPy 10 restarts RBF kernel with normalised Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1) + GPy.kern.White(input_dim=1)\n",
    "# Note: using a white kernel instead of noise_var so that the priors can be specified completely with the kernel rather than requiring access to the model\n",
    "\n",
    "#kernel.rbf.variance.set_prior(GPy.priors.Gamma.from_EV(0.2, 0.1))\n",
    "kernel.rbf.lengthscale.set_prior(GPy.priors.Gamma.from_EV(0.5, 0.1))\n",
    "kernel.white.variance.set_prior(GPy.priors.Gamma.from_EV(0.8, 0.4))\n",
    "\n",
    "gp_model = GPy.models.GPRegression(X, y, kernel=kernel, normalizer=True, noise_var=1e-10)\n",
    "gp_model.optimize_restarts(messages=False, num_restarts=10);\n",
    "display(gp_model)\n",
    "\n",
    "mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "plot_GP(mean, np.sqrt(var), 'GPy 10 restarts RBF kernel with normalised Y with parameter priors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1)\n",
    "gp_model = GPy.models.SparseGPRegression(X, y, kernel=kernel, normalizer=True)\n",
    "gp_model.optimize_restarts(messages=False, num_restarts=10);\n",
    "display(gp_model)\n",
    "\n",
    "gp_model.plot()\n",
    "\n",
    "mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "plot_GP(mean, np.sqrt(var), 'GPy sparse GP 10 restarts RBF kernel with normalised Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(input_dim=1)\n",
    "gp_model = GPy.models.GPRegression(X, y, kernel=kernel, normalizer=True)\n",
    "#gp_model.optimize_restarts(messages=False, num_restarts=10);\n",
    "# from expected value and variance \n",
    "gp_model.kern.variance.set_prior(GPy.priors.Gamma.from_EV(1.0, 1.0))\n",
    "gp_model.kern.lengthscale.set_prior(GPy.priors.Gamma.from_EV(1.0, 1.0))\n",
    "gp_model.likelihood.variance.set_prior(GPy.priors.Gamma.from_EV(1.5, 1))\n",
    "\n",
    "start = time.time()\n",
    "hmc = GPy.inference.mcmc.HMC(gp_model)#, stepsize=5e-2)\n",
    "print('burnin')\n",
    "s = hmc.sample(num_samples=500) # Burnin\n",
    "print('burnin took: {} seconds'.format(time.time()-start))\n",
    "start = time.time()\n",
    "print('sampling')\n",
    "samples = 200\n",
    "s = hmc.sample(num_samples=samples)\n",
    "print('sampling took: {} seconds'.format(time.time()-start))\n",
    "display(gp_model)\n",
    "\n",
    "means = np.empty((samples, xs.shape[0]))\n",
    "sigs = np.empty((samples, xs.shape[0]))\n",
    "for i, params in enumerate(s):\n",
    "    mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "    means[i,:] = mean.flatten()\n",
    "    sigs[i,:] = np.sqrt(var).flatten()\n",
    "mean = np.mean(means, axis=0)\n",
    "sig = np.mean(sigs, axis=0)\n",
    "plot_GP(mean, sig, 'GPy MCMC (averaged predictions) RBF kernel with normalised Y')\n",
    "#plot_GPs(means, sigs, 'GPy MCMC RBF kernel with normalised Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_model[:] = np.mean(s, axis=0)\n",
    "mean, var = gp_model.predict(xs.reshape(-1,1))\n",
    "plot_GP(mean, np.sqrt(var), 'GPy MCMC (averaged parameters) RBF kernel with normalised Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples():\n",
    "    labels = ['kern variance', 'kern lengthscale','noise variance']\n",
    "    from scipy import stats\n",
    "    xmin = s.min()\n",
    "    xmax = s.max()\n",
    "    xs = np.linspace(xmin,xmax,100)\n",
    "    for i in range(s.shape[1]):\n",
    "        kernel = stats.gaussian_kde(s[:,i])\n",
    "        plt.plot(xs,kernel(xs),label=labels[i])\n",
    "    _ = plt.legend()\n",
    "plot_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap():\n",
    "    labels = ['kern variance', 'kern lengthscale','noise variance']\n",
    "    fig = plt.figure(figsize=(14,4))\n",
    "    ax = fig.add_subplot(131)\n",
    "    _=ax.plot(s[:,0],s[:,1],'.')\n",
    "    ax.set_xlabel(labels[0]); ax.set_ylabel(labels[1])\n",
    "    ax = fig.add_subplot(132)\n",
    "    _=ax.plot(s[:,1],s[:,2],'.')\n",
    "    ax.set_xlabel(labels[1]); ax.set_ylabel(labels[2])\n",
    "    ax = fig.add_subplot(133)\n",
    "    _=ax.plot(s[:,0],s[:,2],'.')\n",
    "    ax.set_xlabel(labels[0]); ax.set_ylabel(labels[2])\n",
    "    plt.show()\n",
    "plot_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gp.kernels.RBF()\n",
    "gp_model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y);\n",
    "\n",
    "mean, sig = gp_model.predict(xs.reshape(-1,1), return_std=True)\n",
    "plot_GP(mean, sig, 'scikit 10 restarts RBF kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gp.kernels.RBF() + gp.kernels.WhiteKernel()\n",
    "gp_model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y);\n",
    "\n",
    "mean, sig = gp_model.predict(xs.reshape(-1,1), return_std=True)\n",
    "plot_GP(mean, sig, 'scikit 10 restarts RBF kernel + white kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gp.kernels.RBF() + gp.kernels.WhiteKernel() + 1.0\n",
    "gp_model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y);\n",
    "\n",
    "mean, sig = gp_model.predict(xs.reshape(-1,1), return_std=True)\n",
    "plot_GP(mean, sig, 'scikit 10 restarts RBF kernel + white kernel + bias kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * gp.kernels.RBF() + gp.kernels.WhiteKernel()\n",
    "gp_model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y);\n",
    "\n",
    "mean, sig = gp_model.predict(xs.reshape(-1,1), return_std=True)\n",
    "plot_GP(mean, sig, 'scikit 10 restarts constant * RBF kernel + white kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * gp.kernels.RBF() + gp.kernels.WhiteKernel() + 1.0\n",
    "gp_model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "gp_model.fit(X, y);\n",
    "\n",
    "mean, sig = gp_model.predict(xs.reshape(-1,1), return_std=True)\n",
    "plot_GP(mean, sig, 'scikit 10 restarts constant * RBF kernel + white kernel + bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 1.0 * gp.kernels.RBF() + gp.kernels.WhiteKernel()\n",
    "gp_model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, normalize_y=True)\n",
    "gp_model.fit(X, y);\n",
    "\n",
    "mean, sig = gp_model.predict(xs.reshape(-1,1), return_std=True)\n",
    "plot_GP(mean, sig, 'scikit 10 restarts constant * RBF kernel + white kernel with normalised y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
